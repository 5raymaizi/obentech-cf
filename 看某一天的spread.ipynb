{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看具体某一天的spread数据\n",
    "from backtesting import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_bid_price_spread_plotly(cf_depth,\n",
    "                                 market2_price_col,\n",
    "                                 market1_price_col='market1_bid_price0',\n",
    "                                 q_10_bt=None,\n",
    "                                 q_90_bt=None):\n",
    "    \"\"\"\n",
    "    使用 Plotly 绘制两个市场 bid price 的相对差异（bps），\n",
    "    并在右侧第二坐标轴上叠加 market1 和 market2 的价格曲线。\n",
    "    \"\"\"\n",
    "    # 计算 spread（bps）\n",
    "    spread = ((cf_depth[market2_price_col] / cf_depth[market1_price_col]) - 1) * 10000\n",
    "    # spread = ((cf_depth[market2_price_col] - cf_depth[market1_price_col]))/0.0001\n",
    "    spread.index = cf_depth.index\n",
    "\n",
    "    # 去除极端值\n",
    "    # lower = spread.quantile(0.001)\n",
    "    # upper = spread.quantile(0.999)\n",
    "    # spread_clipped = spread.clip(lower=lower, upper=upper)\n",
    "\n",
    "\n",
    "    spread_clipped = spread.copy()\n",
    "\n",
    "    # 分位数\n",
    "    q10 = spread_clipped.quantile(0.10)\n",
    "    q90 = spread_clipped.quantile(0.90)\n",
    "\n",
    "    # 将UTC时间转换为北京时间（UTC+8）\n",
    "    beijing_time = cf_depth.index.tz_localize('UTC').tz_convert('Asia/Shanghai')\n",
    "    cf_depth['beijing_time'] = beijing_time\n",
    "    # 创建图\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # —— Spread 曲线（左侧 y 轴）——\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=beijing_time,\n",
    "        y=spread_clipped,\n",
    "        mode='lines',\n",
    "        name='Spread (bps)',\n",
    "        line=dict(color='purple'),\n",
    "        yaxis='y1'\n",
    "    ))\n",
    "    #10% / 90% 分位线\n",
    "    for val, name, dash_color in [\n",
    "        (q10, f'10% Quantile: {q10:.2f}', 'red'),\n",
    "        (q90, f'90% Quantile: {q90:.2f}', 'green'),\n",
    "        (q_10_bt, f'10% Quantile (backtest): {q_10_bt:.2f}', 'blue'),\n",
    "        (q_90_bt, f'90% Quantile (backtest): {q_90_bt:.2f}', 'orange'),\n",
    "    ]:\n",
    "        if val is not None:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[beijing_time[0], beijing_time[-1]],\n",
    "                y=[val, val],\n",
    "                mode='lines',\n",
    "                name=name,\n",
    "                line=dict(color=dash_color, dash='dash'),\n",
    "                yaxis='y1'\n",
    "            ))\n",
    "\n",
    "    # —— 价格曲线（右侧 y 轴）——\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=beijing_time,\n",
    "        y=cf_depth[market1_price_col],\n",
    "        mode='lines',\n",
    "        name=f'{market1_price_col}(binance)',\n",
    "        yaxis='y2'\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=beijing_time,\n",
    "        y=cf_depth[market2_price_col],\n",
    "        mode='lines',\n",
    "        name=f'{market2_price_col}(okx)',\n",
    "        yaxis='y2'\n",
    "    ))\n",
    "\n",
    "    # 布局：定义两个纵轴\n",
    "    fig.update_layout(\n",
    "        title=f'Spread & Prices: {market2_price_col} vs {market1_price_col}',\n",
    "        xaxis=dict(title='Time (Beijing)'),\n",
    "        yaxis=dict(\n",
    "            title='Spread (bps)',\n",
    "            side='left',\n",
    "            showgrid=False,\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='Price',\n",
    "            overlaying='y',\n",
    "            side='right',\n",
    "            showgrid=False,\n",
    "        ),\n",
    "        hovermode='x unified',\n",
    "        height=1200,\n",
    "        width=2400,\n",
    "        legend=dict(x=0.01, y=0.99)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    return cf_depth\n",
    "\n",
    "def plot_bid_price_spread_matplotlib(cf_depth,\n",
    "                                     market2_price_col,\n",
    "                                     market1_price_col='market1_bid_price0',\n",
    "                                     q_10_bt=None,\n",
    "                                     q_90_bt=None):\n",
    "    \"\"\"\n",
    "    使用 Matplotlib 绘制两个市场 bid price 的相对差异（bps），\n",
    "    并在右侧第二坐标轴上叠加 market1 和 market2 的价格曲线。\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # 计算 spread（bps）\n",
    "    spread = ((cf_depth[market2_price_col] / cf_depth[market1_price_col]) - 1) * 10000\n",
    "    spread.index = cf_depth.index\n",
    "\n",
    "    # 去除极端值\n",
    "    # lower = spread.quantile(0.001)\n",
    "    # upper = spread.quantile(0.999)\n",
    "    # spread_clipped = spread.clip(lower=lower, upper=upper)\n",
    "    spread_clipped = spread.copy()\n",
    "\n",
    "    # 分位数\n",
    "    q10 = spread_clipped.quantile(0.10)\n",
    "    q90 = spread_clipped.quantile(0.90)\n",
    "\n",
    "    # 将UTC时间转换为北京时间（UTC+8）\n",
    "    beijing_time = cf_depth.index.tz_localize('UTC').tz_convert('Asia/Shanghai')\n",
    "    cf_depth['beijing_time'] = beijing_time\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(24, 12))\n",
    "\n",
    "    # —— Spread 曲线（左侧 y 轴）——\n",
    "    ax1.plot(beijing_time, spread_clipped, color='purple', label='Spread (bps)')\n",
    "    # 10% / 90% 分位线\n",
    "    for val, name, color in [\n",
    "        (q10, f'10% Quantile: {q10:.2f}', 'red'),\n",
    "        (q90, f'90% Quantile: {q90:.2f}', 'green'),\n",
    "        (q_10_bt, f'10% Quantile (backtest): {q_10_bt:.2f}', 'blue'),\n",
    "        (q_90_bt, f'90% Quantile (backtest): {q_90_bt:.2f}', 'orange'),\n",
    "    ]:\n",
    "        if val is not None:\n",
    "            ax1.axhline(y=val, color=color, linestyle='--', label=name)\n",
    "\n",
    "    ax1.set_ylabel('Spread (bps)')\n",
    "    ax1.set_xlabel('Time (Beijing)')\n",
    "    ax1.grid(False)\n",
    "\n",
    "    # —— 价格曲线（右侧 y 轴）——\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(beijing_time, cf_depth[market1_price_col], color='black', label=f'{market1_price_col}(binance)')\n",
    "    ax2.plot(beijing_time, cf_depth[market2_price_col], color='gray', label=f'{market2_price_col}(okx)')\n",
    "    ax2.set_ylabel('Price')\n",
    "    ax2.grid(False)\n",
    "\n",
    "    # 合并图例\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
    "\n",
    "    plt.title(f'Spread & Prices: {market2_price_col} vs {market1_price_col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return cf_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cf_depth(ccy, start_date, end_date, exchange1, market1, exchange2, market2, data_source):\n",
    "    if data_source == 'inner_win':\n",
    "        market1_depth_path = f'/Users/rayxu/Desktop/Obentech/dcdlData/{exchange1}/books/{ccy}/{market1}'\n",
    "        market2_depth_path = f'/Users/rayxu/Desktop/Obentech/dcdlData/{exchange2}/books/{ccy}/{market2}'\n",
    "    elif data_source == 'outer_ssd':\n",
    "        market1_depth_path = f'/Volumes/T7/Obentech/dcdlData/{exchange1}/books/{ccy}/{market1}'\n",
    "        market2_depth_path = f'/Volumes/T7/Obentech/dcdlData/{exchange2}/books/{ccy}/{market2}'\n",
    "    elif data_source =='nuts_mm':\n",
    "        market1_depth_path = f'/Users/rayxu/Downloads/nuts_am/data/{exchange1}/perp/books/{ccy}'\n",
    "        market2_depth_path = f'/Users/rayxu/Downloads/nuts_am/data/{exchange2}/perp/books/{ccy}'\n",
    "\n",
    "    if data_source == 'nuts_mm':\n",
    "        market1_depth = pd.concat([pd.read_parquet(f'{market1_depth_path}/{ccy}usdt_{dd}_depth5.parquet')\n",
    "                            for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])        \n",
    "        market2_depth = pd.concat([pd.read_parquet(f'{market2_depth_path}/{ccy}usdt_{dd}_depth5.parquet')\n",
    "                            for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])\n",
    "    else:\n",
    "        market1_depth = pd.concat([pd.read_csv(f'{market1_depth_path}/{ccy}usdt_{dd}_depth5.csv')\n",
    "                          for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])        \n",
    "        market2_depth = pd.concat([pd.read_csv(f'{market2_depth_path}/{ccy}usdt_{dd}_depth5.csv')\n",
    "                          for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])\n",
    "    # 不知道为啥24年的数据，是23年的年份，所以先加1年处理\n",
    "    # market1_depth[\"received_time\"] = pd.to_datetime(market1_depth[\"received_time\"]).apply(lambda x:x+relativedelta(years=1))\n",
    "    time_col = get_time_col(exchange1,exchange2)\n",
    "    market1_depth[time_col] = pd.to_datetime(market1_depth[time_col], unit = 'ms')\n",
    "    market1_depth.set_index(time_col, inplace=True)\n",
    "    market1_depth['ws_type'] = \"market1_depth\"\n",
    "    market1_depth.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "    # 不知道为啥24年的数据，是23年的年份，所以先加1年处理\n",
    "    # market2_depth[\"received_time\"] = pd.to_datetime(market2_depth[\"received_time\"]).apply(lambda x:x+relativedelta(years=1))\n",
    "    market2_depth[time_col] = pd.to_datetime(market2_depth[time_col], unit = 'ms')\n",
    "    market2_depth.set_index(time_col, inplace=True)\n",
    "    market2_depth['ws_type'] = \"market2_depth\"\n",
    "    market2_depth.drop_duplicates(inplace=True)\n",
    "    \n",
    "    market1_depth.columns = rename_columns(list(market1_depth.columns), 'market1_')\n",
    "    market2_depth.columns = rename_columns(list(market2_depth.columns), 'market2_')\n",
    "########################################################################################\n",
    "# 04-21修改： 改用merge_asof\n",
    "    # 保证时间索引已经在 column 中（因为 merge_asof 不能用 index 作为 on）\n",
    "    market1_depth = market1_depth.reset_index()\n",
    "    market2_depth = market2_depth.reset_index()\n",
    "\n",
    "    # 使用 merge_asof 精准时间对齐，100ms 容差，向后对齐\n",
    "    cf_depth = pd.merge_asof(\n",
    "        market1_depth.sort_values(time_col),\n",
    "        market2_depth.sort_values(time_col),\n",
    "        on=time_col,\n",
    "        direction='backward',\n",
    "        tolerance=pd.Timedelta('100ms'),\n",
    "        suffixes=('_market1', '_market2')\n",
    "    )\n",
    "\n",
    "    cf_depth[['market1_ws_type', 'market2_ws_type']] = cf_depth[['market1_ws_type', 'market2_ws_type']].fillna('')\n",
    "    cf_depth['ws_type'] = cf_depth['market1_ws_type'] + cf_depth['market2_ws_type']\n",
    "    \n",
    "    cf_depth.dropna(inplace=True)\n",
    "    cf_depth = cf_depth.fillna(method='ffill').assign(\n",
    "        sp_open=lambda df: df['market2_bid_price1']-df['market1_ask_price1'],\n",
    "        sp_close=lambda df: df['market2_ask_price1']-df['market1_bid_price1'],\n",
    "        sr_open=lambda df: df['sp_open']/df['market1_ask_price1'],\n",
    "        sr_close=lambda df: df['sp_close']/df['market1_bid_price1'],\n",
    "        # 用midprice计算\n",
    "        midprice=lambda df: (df['market1_bid_price1'] + df['market1_ask_price1']) / 2\n",
    "    )\n",
    "    \n",
    "    # 计算过去N个tick的收益率（用midprice）\n",
    "    for n in [10, 50, 100, 300, 600]:\n",
    "        cf_depth[f'ret_mid_{n/10}s'] = cf_depth['midprice'].pct_change(periods=n)\n",
    "        cf_depth[f'logret_mid_{n/10}s'] = np.log(cf_depth['midprice'] / cf_depth['midprice'].shift(n))\n",
    "    \n",
    "    cf_depth.reset_index(inplace=True)\n",
    "    cf_depth['received_time_diff_1jump_later'] = cf_depth[time_col].shift(-1) - cf_depth[time_col]\n",
    "    cf_depth['received_time_diff_1jump_later'] = cf_depth['received_time_diff_1jump_later'].apply(lambda x:x.total_seconds())\n",
    "    cf_depth.set_index(time_col, inplace=True)\n",
    "    cf_depth_st_index = cf_depth.index[0]\n",
    "    cf_depth_et_index = cf_depth.index[-1]\n",
    "    \n",
    "    return cf_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cf_depth(ccy, start_date, end_date, exchange1, market1, exchange2, market2, data_source):\n",
    "    if data_source == 'inner_win':\n",
    "        market1_depth_path = f'/Users/rayxu/Desktop/Obentech/dcdlData/{exchange1}/books/{ccy}/{market1}'\n",
    "        market2_depth_path = f'/Users/rayxu/Desktop/Obentech/dcdlData/{exchange2}/books/{ccy}/{market2}'\n",
    "    elif data_source == 'outer_ssd':\n",
    "        market1_depth_path = f'/Volumes/T7/Obentech/dcdlData/{exchange1}/books/{ccy}/{market1}'\n",
    "        market2_depth_path = f'/Volumes/T7/Obentech/dcdlData/{exchange2}/books/{ccy}/{market2}'\n",
    "    elif data_source =='nuts_mm':\n",
    "        market1_depth_path = f'/Volumes/T7/data/{exchange1}/perp/books/{ccy}'\n",
    "        market2_depth_path = f'/Volumes/T7/data/{exchange2}/perp/books/{ccy}'\n",
    "\n",
    "    if data_source == 'nuts_mm':\n",
    "        market1_depth = pd.concat([pd.read_parquet(f'{market1_depth_path}/{ccy}usdt_{dd}_depth5.parquet')\n",
    "                            for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])        \n",
    "        market2_depth = pd.concat([pd.read_parquet(f'{market2_depth_path}/{ccy}usdt_{dd}_depth5.parquet')\n",
    "                            for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])\n",
    "    else:\n",
    "        market1_depth = pd.concat([pd.read_csv(f'{market1_depth_path}/{ccy}usdt_{dd}_depth5.csv')\n",
    "                          for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])        \n",
    "        market2_depth = pd.concat([pd.read_csv(f'{market2_depth_path}/{ccy}usdt_{dd}_depth5.csv')\n",
    "                          for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])\n",
    "    # 不知道为啥24年的数据，是23年的年份，所以先加1年处理\n",
    "    # market1_depth[\"received_time\"] = pd.to_datetime(market1_depth[\"received_time\"]).apply(lambda x:x+relativedelta(years=1))\n",
    "    time_col = get_time_col(exchange1,exchange2)\n",
    "    market1_depth[time_col] = pd.to_datetime(market1_depth[time_col], unit = 'ms')\n",
    "    market1_depth.set_index(time_col, inplace=True)\n",
    "    market1_depth['ws_type'] = \"market1_depth\"\n",
    "    # market1_depth.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 不知道为啥24年的数据，是23年的年份，所以先加1年处理\n",
    "    # market2_depth[\"received_time\"] = pd.to_datetime(market2_depth[\"received_time\"]).apply(lambda x:x+relativedelta(years=1))\n",
    "    market2_depth[time_col] = pd.to_datetime(market2_depth[time_col], unit = 'ms')\n",
    "    market2_depth.set_index(time_col, inplace=True)\n",
    "    market2_depth['ws_type'] = \"market2_depth\"\n",
    "    # market2_depth.drop_duplicates(inplace=True)\n",
    "    \n",
    "    market1_depth.columns = rename_columns(list(market1_depth.columns), 'market1_')\n",
    "    market2_depth.columns = rename_columns(list(market2_depth.columns), 'market2_')\n",
    "########################################################################################\n",
    "# 04-21修改： 改用merge_asof\n",
    "    # 保证时间索引已经在 column 中（因为 merge_asof 不能用 index 作为 on）\n",
    "    market1_depth = market1_depth.reset_index()\n",
    "    market2_depth = market2_depth.reset_index()\n",
    "\n",
    "    # 使用 merge_asof 精准时间对齐，100ms 容差，向后对齐\n",
    "    cf_depth = pd.merge_asof(\n",
    "        market1_depth.sort_values(time_col),\n",
    "        market2_depth.sort_values(time_col),\n",
    "        on=time_col,\n",
    "        direction='backward',\n",
    "        tolerance=pd.Timedelta('100ms'),\n",
    "        suffixes=('_market1', '_market2')\n",
    "    )\n",
    "\n",
    "    cf_depth[['market1_ws_type', 'market2_ws_type']] = cf_depth[['market1_ws_type', 'market2_ws_type']].fillna('')\n",
    "    cf_depth['ws_type'] = cf_depth['market1_ws_type'] + cf_depth['market2_ws_type']\n",
    "    \n",
    "    cf_depth.dropna(inplace=True)\n",
    "    cf_depth = cf_depth.fillna(method='ffill').assign(\n",
    "        sp_open=lambda df: df['market2_bid_price1']-df['market1_ask_price1'],\n",
    "        sp_close=lambda df: df['market2_ask_price1']-df['market1_bid_price1'],\n",
    "        sr_open=lambda df: df['sp_open']/df['market1_ask_price1'],\n",
    "        sr_close=lambda df: df['sp_close']/df['market1_bid_price1'],\n",
    "        # 用midprice计算\n",
    "        midprice=lambda df: (df['market1_bid_price1'] + df['market1_ask_price1']) / 2\n",
    "    )\n",
    "    \n",
    "    # 计算过去N个tick的收益率（用midprice）\n",
    "    for n in [10, 50, 100, 300, 600]:\n",
    "        cf_depth[f'ret_mid_{n/10}s'] = cf_depth['midprice'].pct_change(periods=n)\n",
    "        cf_depth[f'logret_mid_{n/10}s'] = np.log(cf_depth['midprice'] / cf_depth['midprice'].shift(n))\n",
    "    \n",
    "    # 计算过去60s和5s的波动率，并计算它们的比值\n",
    "    # 假设tick大约0.1s一个，60s窗口大约600个tick，5s窗口大约50个tick\n",
    "    # 这里用midprice的对数收益率的rolling std来衡量波动率\n",
    "    cf_depth['logret_mid_1tick'] = np.log(cf_depth['midprice'] / cf_depth['midprice'].shift(1))\n",
    "    cf_depth['vol_60s'] = cf_depth['logret_mid_1tick'].rolling(window=600, min_periods=600).std()\n",
    "    cf_depth['vol_5s'] = cf_depth['logret_mid_1tick'].rolling(window=50, min_periods=50).std()\n",
    "    cf_depth['vol_60s_div_5s'] = cf_depth['vol_60s'] / cf_depth['vol_5s']\n",
    "    # 你可以直接用 cf_depth['vol_60s_div_5s'] 这一列\n",
    "\n",
    "    cf_depth.reset_index(inplace=True)\n",
    "    cf_depth['received_time_diff_1jump_later'] = cf_depth[time_col].shift(-1) - cf_depth[time_col]\n",
    "    cf_depth['received_time_diff_1jump_later'] = cf_depth['received_time_diff_1jump_later'].apply(lambda x:x.total_seconds())\n",
    "    cf_depth.set_index(time_col, inplace=True)\n",
    "    cf_depth_st_index = cf_depth.index[0]\n",
    "    cf_depth_et_index = cf_depth.index[-1]\n",
    "    \n",
    "    return cf_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cf_depth_using_local_time(ccy, start_date, end_date, exchange1, market1, exchange2, market2, data_source):\n",
    "    if data_source == 'inner_win':\n",
    "        market1_depth_path = f'/Users/rayxu/Desktop/Obentech/dcdlData/{exchange1}/books/{ccy}/{market1}'\n",
    "        market2_depth_path = f'/Users/rayxu/Desktop/Obentech/dcdlData/{exchange2}/books/{ccy}/{market2}'\n",
    "    elif data_source == 'outer_ssd':\n",
    "        market1_depth_path = f'/Volumes/T7/Obentech/dcdlData/{exchange1}/books/{ccy}/{market1}'\n",
    "        market2_depth_path = f'/Volumes/T7/Obentech/dcdlData/{exchange2}/books/{ccy}/{market2}'\n",
    "    elif data_source == 'nuts_mm':\n",
    "        market1_depth_path = f'/Volumes/T7/data/{exchange1}/perp/books/{ccy}'\n",
    "        market2_depth_path = f'/Volumes/T7/data/{exchange2}/perp/books/{ccy}'\n",
    "    # if data_source == 'nuts_am_on_mac':\n",
    "    #     market1_depth_path = f'/Users/rayxu/Downloads/nuts_am/data/{exchange1}/perp/books/{ccy}'\n",
    "    #     market2_depth_path = f'/Users/rayxu/Downloads/nuts_am/data/{exchange2}/perp/books/{ccy}'\n",
    "        market1_depth = pd.concat([pd.read_parquet(f'{market1_depth_path}/{ccy}usdt_{dd}_depth5.parquet')\n",
    "                            for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])        \n",
    "        market2_depth = pd.concat([pd.read_parquet(f'{market2_depth_path}/{ccy}usdt_{dd}_depth5.parquet')\n",
    "                            for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])\n",
    "    # else:\n",
    "    #     market1_depth = pd.concat([pd.read_csv(f'{market1_depth_path}/{ccy}usdt_{dd}_depth5.csv')\n",
    "    #                       for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])        \n",
    "    #     market2_depth = pd.concat([pd.read_csv(f'{market2_depth_path}/{ccy}usdt_{dd}_depth5.csv')\n",
    "    #                       for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])\n",
    "\n",
    "    time_col = 'received_time'\n",
    "    market1_depth[time_col] = pd.to_datetime(market1_depth[time_col])\n",
    "    market1_depth.set_index(time_col, inplace=True)\n",
    "    market1_depth['ws_type'] = \"market1_depth\"\n",
    "    # market1_depth.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "    market2_depth[time_col] = pd.to_datetime(market2_depth[time_col])\n",
    "    market2_depth.set_index(time_col, inplace=True)\n",
    "    market2_depth['ws_type'] = \"market2_depth\"\n",
    "    # market2_depth.drop_duplicates(inplace=True)\n",
    "    \n",
    "    market1_depth.columns = rename_columns(list(market1_depth.columns), 'market1_')\n",
    "    market2_depth.columns = rename_columns(list(market2_depth.columns), 'market2_')\n",
    "    ########################################################################################\n",
    "    # 04-21修改： 改用merge_asof\n",
    "    # 保证时间索引已经在 column 中（因为 merge_asof 不能用 index 作为 on）\n",
    "    market1_depth = market1_depth.reset_index()\n",
    "    market2_depth = market2_depth.reset_index()\n",
    "\n",
    "    # 使用 merge_asof 精准时间对齐，100ms 容差，向后对齐\n",
    "    cf_depth = pd.merge_asof(\n",
    "        market1_depth.sort_values(time_col),\n",
    "        market2_depth.sort_values(time_col),\n",
    "        on=time_col,\n",
    "        direction='backward',\n",
    "        tolerance=pd.Timedelta('100ms'),\n",
    "        suffixes=('_market1', '_market2')\n",
    "    )\n",
    "\n",
    "    cf_depth[['market1_ws_type', 'market2_ws_type']] = cf_depth[['market1_ws_type', 'market2_ws_type']].fillna('')\n",
    "    cf_depth['ws_type'] = cf_depth['market1_ws_type'] + cf_depth['market2_ws_type']\n",
    "    \n",
    "    cf_depth.dropna(inplace=True)\n",
    "    cf_depth = cf_depth.fillna(method='ffill').assign(\n",
    "        sp_open=lambda df: df['market2_bid_price1']-df['market1_ask_price1'],\n",
    "        sp_close=lambda df: df['market2_ask_price1']-df['market1_bid_price1'],\n",
    "        sr_open=lambda df: df['sp_open']/df['market1_ask_price1'],\n",
    "        sr_close=lambda df: df['sp_close']/df['market1_bid_price1'],\n",
    "        # 用midprice计算\n",
    "        midprice=lambda df: (df['market1_bid_price1'] + df['market1_ask_price1']) / 2\n",
    "    )\n",
    "\n",
    "    # # 计算过去N个tick的收益率（用midprice）\n",
    "    # for n in [10, 50, 100, 300, 600]:\n",
    "    #     cf_depth[f'ret_mid_{n/10}s'] = cf_depth['midprice'].pct_change(periods=n)\n",
    "    #     cf_depth[f'logret_mid_{n/10}s'] = np.log(cf_depth['midprice'] / cf_depth['midprice'].shift(n))\n",
    "    \n",
    "    cf_depth.reset_index(inplace=True)\n",
    "    # cf_depth['received_time_diff_1jump_later'] = cf_depth[time_col].shift(-1) - cf_depth[time_col]\n",
    "    # cf_depth['received_time_diff_1jump_later'] = cf_depth['received_time_diff_1jump_later'].apply(lambda x:x.total_seconds())\n",
    "    cf_depth.set_index(time_col, inplace=True)\n",
    "    beijing_time = cf_depth.index.tz_localize('UTC').tz_convert('Asia/Shanghai').tz_localize(None)\n",
    "    cf_depth['beijing_time'] = beijing_time\n",
    "    cf_depth_st_index = cf_depth.index[0]\n",
    "    cf_depth_et_index = cf_depth.index[-1]\n",
    "    \n",
    "    return cf_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cf_depth_backtesting(ccy, start_date, end_date, exchange1, market1, exchange2, market2, data_source, isUseLocalTime = False):\n",
    "\n",
    "    if data_source == 'nuts_mm':\n",
    "        market1_depth_path = f'/Volumes/T7/data/{exchange1}/perp/books/{ccy}'\n",
    "        market2_depth_path = f'/Volumes/T7/data/{exchange2}/perp/books/{ccy}'\n",
    "        market1_depth = pd.concat([pd.read_parquet(f'{market1_depth_path}/{ccy}usdt_{dd}_depth5.parquet')\n",
    "                            for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])        \n",
    "        market2_depth = pd.concat([pd.read_parquet(f'{market2_depth_path}/{ccy}usdt_{dd}_depth5.parquet')\n",
    "                            for dd in pd.date_range(start_date, end_date).strftime('%Y-%m-%d')])\n",
    "    if isUseLocalTime:\n",
    "        time_col = 'received_time'\n",
    "        market1_depth[time_col] = pd.to_datetime(market1_depth[time_col])\n",
    "        market2_depth[time_col] = pd.to_datetime(market2_depth[time_col])\n",
    "    else:\n",
    "        time_col = 'T'\n",
    "        market1_depth[time_col] = pd.to_datetime(market1_depth[time_col], unit='ms')\n",
    "        market2_depth[time_col] = pd.to_datetime(market2_depth[time_col], unit='ms')\n",
    "\n",
    "    market1_depth.set_index(time_col, inplace=True)\n",
    "    market1_depth['ws_type'] = \"market1_depth\"\n",
    "    # market1_depth.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "    market2_depth.set_index(time_col, inplace=True)\n",
    "    market2_depth['ws_type'] = \"market2_depth\"\n",
    "    # market2_depth.drop_duplicates(inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "    ########################################################################################\n",
    "    # 04-21修改： 改用merge_asof\n",
    "    # 保证时间索引已经在 column 中（因为 merge_asof 不能用 index 作为 on）\n",
    "    market1_depth = market1_depth.reset_index()\n",
    "    market2_depth = market2_depth.reset_index()\n",
    "\n",
    "    merged_time = pd.Series(\n",
    "        sorted(set(market1_depth[time_col]) | set(market2_depth[time_col]))\n",
    "    )\n",
    "\n",
    "\n",
    "    market1_depth_full = pd.merge_asof(merged_time.to_frame(time_col), market1_depth.sort_values(time_col),\n",
    "                            on=time_col, direction='backward',tolerance=pd.Timedelta('100ms'))\n",
    "    market2_depth_full = pd.merge_asof(merged_time.to_frame(time_col), market2_depth.sort_values(time_col),\n",
    "                            on=time_col, direction='backward',tolerance=pd.Timedelta('100ms'))\n",
    "                            \n",
    "    merged_depth = pd.concat(\n",
    "        [market1_depth_full.add_prefix('market1_'), market2_depth_full.add_prefix('market2_')], axis=1\n",
    "    )\n",
    "    merged_depth[time_col] = merged_time.values\n",
    "    merged_depth['sr_open'] = (merged_depth['market2_ask_price0']/merged_depth['market1_ask_price0']-1)*10000\n",
    "    merged_depth['sr_close'] = (merged_depth['market2_bid_price0']/merged_depth['market1_bid_price0']-1)*10000\n",
    "    cf_depth = merged_depth.dropna()\n",
    "\n",
    "    cf_depth.reset_index(inplace=True)\n",
    "    cf_depth.set_index(time_col, inplace=True)\n",
    "    if not isUseLocalTime:\n",
    "        beijing_time = cf_depth.index.tz_localize('UTC').tz_convert('Asia/Shanghai').tz_localize(None)\n",
    "        cf_depth['beijing_time'] = beijing_time\n",
    "    else:\n",
    "        cf_depth['beijing_time'] = cf_depth.index\n",
    "        \n",
    "    cf_depth = cf_depth.sort_index()\n",
    "    # rolling('5s') 表示时间窗口5秒；center=False表示只看过去\n",
    "    cf_depth['sr_open_median_5s'] = cf_depth['sr_open'].rolling('5s').median()\n",
    "    cf_depth['sr_open_median_10s'] = cf_depth['sr_open'].rolling('10s').median()\n",
    "    cf_depth['sr_open_median_30s'] = cf_depth['sr_open'].rolling('30s').median()\n",
    "    cf_depth['sr_close_median_5s'] = cf_depth['sr_close'].rolling('5s').median()\n",
    "    cf_depth['sr_close_median_10s'] = cf_depth['sr_close'].rolling('10s').median()\n",
    "    cf_depth['sr_close_median_30s'] = cf_depth['sr_close'].rolling('30s').median()\n",
    "    return cf_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cf_depth_history_1min(ccy, start_date, end_date,data_source):\n",
    "\n",
    "    ccy = symbol\n",
    "    # 读聚合后的深度数据（你已有函数）\n",
    "    cf_depth = pd.read_csv(f'/Volumes/T7/Obentech/historyDepthData/depth_okx_binance_{symbol.lower()}-usdt_1min.csv')\n",
    "    cf_depth['event_time'] = pd.to_datetime(cf_depth['event_time'], unit='ms')\n",
    "    cf_depth['beijing_time'] = cf_depth['event_time']+pd.Timedelta(hours=8)\n",
    "    cf_depth = cf_depth[(cf_depth['beijing_time']>=pd.to_datetime(st)) & (cf_depth['beijing_time']<=pd.to_datetime(et))]\n",
    "    cf_depth.set_index('beijing_time', inplace=True)\n",
    "    # 增加最后一个时间点00:00:00（之前是到23:59:59）\n",
    "    st = pd.to_datetime(st)\n",
    "    et = pd.to_datetime(et)\n",
    "    end_midnight = et + pd.Timedelta(days=1) \n",
    "\n",
    "    spread_bid = cf_depth['avg_sr_bid']\n",
    "    spread_ask = cf_depth['avg_sr_ask']\n",
    "    return cf_depth, spread_bid, spread_ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'TON'\n",
    "st='2026-02-11'\n",
    "et='2026-02-11'\n",
    "# train_st='2025-07-01'\n",
    "# train_et='2025-07-18'\n",
    "exchange1='binance' \n",
    "market1='swap'\n",
    "exchange2='okx'     \n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "order_type = 'MT'\n",
    "data_source = \"nuts_mm\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_depth = read_cf_depth(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "# cf_depth = read_cf_depth_backtesting(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "# cf_depth = cf_depth[::50]\n",
    "cf_depth_train = cf_depth.copy()\n",
    "\n",
    "spread_bid = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "spread_ask = ((cf_depth_train['market2_ask_price0'] / cf_depth_train['market1_ask_price0']) - 1) * 10000\n",
    "q10_train = spread_bid.quantile(close_quantile)\n",
    "q90_train = spread_ask.quantile(open_quantile)\n",
    "\n",
    "target_open_sr = q90_train/10000\n",
    "target_close_sr = q10_train/10000\n",
    "\n",
    "# plot_bid_price_spread_plotly(cf_depth, 'market2_ask_price0','market1_ask_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_ask.quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_bid.quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_ask.quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_bid.quantile(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_bid_reverse = (cf_depth_train['market1_bid_price0'] / cf_depth_train['market2_bid_price0'] - 1) * 10000\n",
    "spread_ask_reverse = (cf_depth_train['market1_ask_price0'] / cf_depth_train['market2_ask_price0'] - 1) * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spread_bid_reverse.quantile(0.05))\n",
    "print(spread_ask_reverse.quantile(0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth['beijing_time'] = cf_depth['beijing_time'].dt.tz_localize(None)\n",
    "cf_depth['ESRA'] = (cf_depth['market2_ask_price0']/cf_depth['market1_ask_price0']-1)\n",
    "cf_depth[cf_depth['beijing_time']>pd.to_datetime('2025-09-25 10:10:56')].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def count_crossings(spread_series: pd.Series, lower: float, upper: float) -> int:\n",
    "    in_long = False\n",
    "    in_short = False\n",
    "    count = 0\n",
    "\n",
    "    for x in spread_series:\n",
    "        if not in_long and x < lower:\n",
    "            in_long = True\n",
    "        elif in_long and x > upper:\n",
    "            count += 1\n",
    "            in_long = False\n",
    "\n",
    "        if not in_short and x > upper:\n",
    "            in_short = True\n",
    "        elif in_short and x < lower:\n",
    "            count += 1\n",
    "            in_short = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def find_best_threshold(spread_series: pd.Series, threshold_gap=0.00015, step=5e-5):\n",
    "    min_spread = -0.0005\n",
    "    max_spread = 0.0005\n",
    "    \n",
    "    best_lower = None\n",
    "    best_upper = None\n",
    "    max_count = 0\n",
    "\n",
    "    for lower in np.arange(min_spread, max_spread - threshold_gap, step):\n",
    "        upper = lower + threshold_gap\n",
    "        count = count_crossings(spread_series, lower, upper)\n",
    "        print(lower,upper,count)\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            best_lower = lower\n",
    "            best_upper = upper\n",
    "\n",
    "    return best_lower, best_upper, max_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 spread_series 是你的价差数据\n",
    "best_lower, best_upper, max_crossings = find_best_threshold(spread_bid/10000, threshold_gap = 0.00015, step = 0.00001)\n",
    "print(f\"Best lower: {best_lower:.5f}, upper: {best_upper:.5f}, crossings: {max_crossings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "最近30天：\n",
    "-0.00008, 0.00007\n",
    "\n",
    "最近15天：\n",
    "-0.0001, 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q90_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这行代码的意思是：从 spread_bid 这个 Series 里每隔1000个取一个元素（即每1000个取一个），用于采样查看数据的分布或趋势。\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sampled = spread_bid[::100000]\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(sampled.index, sampled.values, linestyle='-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Spread Bid')\n",
    "plt.title('Spread Bid vs Time ')\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth = plot_bid_price_spread_matplotlib(cf_depth, 'market2_ask_price0','market1_ask_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q90_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth.head(300)['market2_ask_price0'].plot()\n",
    "print(calc_trend_r2(cf_depth.head(300)['market2_ask_price0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth[100:400]['market2_ask_price0'].plot()\n",
    "print(calc_trend_r2(cf_depth[100:400]['market2_ask_price0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth[300:600]['market2_ask_price0'].plot()\n",
    "print(calc_trend_r2(cf_depth[300:600]['market2_ask_price0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def calc_trend_r2(efficient_rm):\n",
    "    if efficient_rm.size < 2:       # 少于2个点无法回归\n",
    "        return 0.0, 0.0\n",
    "    prices = np.array(list(efficient_rm))[::-1]\n",
    "    y = (prices / prices[0] - 1)\n",
    "    X = np.linspace(0, 1, len(prices)).reshape(-1, 1)\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    return model.coef_[0], model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_trend_r2(cf_depth.head(300)['market2_ask_price0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth = plot_bid_price_spread_plotly(cf_depth, 'market2_ask_price0','market1_ask_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train.quantile(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train.quantile(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q90_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q90_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按天统计spread的95%和5%分位，index是datetime格式\n",
    "\n",
    "# 计算spread\n",
    "spread = ((cf_depth['market2_bid_price0'] / cf_depth['market1_bid_price0']) - 1) * 10000\n",
    "\n",
    "# 用index的日期部分直接分组，无需新建date列\n",
    "# 如果index不是DatetimeIndex，先转一下\n",
    "if not isinstance(cf_depth.index, pd.DatetimeIndex):\n",
    "    cf_depth = cf_depth.copy()\n",
    "    cf_depth.index = pd.to_datetime(cf_depth.index)\n",
    "\n",
    "# 按天统计95分位和5分位\n",
    "daily_quantiles = spread.groupby(cf_depth.index.date).quantile([0.05, 0.95]).unstack()\n",
    "daily_quantiles.columns = ['5%_quantile', '95%_quantile']\n",
    "daily_quantiles = daily_quantiles.reset_index(names='date')\n",
    "\n",
    "print(daily_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/Users/rayxu/Downloads/cfdc_dcpro1_stat(1).csv').sort_values('net_amount_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bid_price_spread_matplotlib(cf_depth, 'market2_bid_price0','market1_bid_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q90_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'ALCH'\n",
    "st='2025-07-15'\n",
    "et='2025-07-21'\n",
    "# train_st='2025-07-01'\n",
    "# train_et='2025-07-03'\n",
    "exchange1='binance' \n",
    "market1='swap'\n",
    "exchange2='okx'     \n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "order_type = 'MT'\n",
    "data_source = \"outer_ssd\"\n",
    "\n",
    "\n",
    "\n",
    "# cf_depth_train = read_cf_depth(ccy, train_st, train_et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "cf_depth = read_cf_depth(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "\n",
    "\n",
    "spread_train = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "# spread_train = ((cf_depth_train['market2_bid_price0'] - cf_depth_train['market1_bid_price0']))\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)\n",
    "\n",
    "target_open_sr = q90_train/10000\n",
    "target_close_sr = q10_train/10000\n",
    "\n",
    "# plot_bid_price_spread_plotly(cf_depth, 'market2_bid_price0','market1_bid_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)\n",
    "plot_bid_price_spread_plotly(cf_depth, 'market2_bid_price0','market1_bid_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00 = cf_depth[(cf_depth.index>=pd.to_datetime('2025-07-02 15:00:00'))&(cf_depth.index<pd.to_datetime('2025-07-02 16:00:00'))].copy()\n",
    "spread_train = ((df_00['market2_bid_price0'] / df_00['market1_bid_price0']) - 1) * 10000\n",
    "print(spread_train.quantile(0.05),spread_train.quantile(0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = cf_depth[(cf_depth.index>=pd.to_datetime('2025-07-01 17:00:00'))&(cf_depth.index<pd.to_datetime('2025-07-02 17:00:00'))].copy()\n",
    "spread_train = ((df_01['market2_bid_price0'] / df_01['market1_bid_price0']) - 1) * 10000\n",
    "print(spread_train.quantile(0.05),spread_train.quantile(0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_02 = cf_depth[(cf_depth.index>=pd.to_datetime('2025-07-01 18:00:00'))&(cf_depth.index<pd.to_datetime('2025-07-02 18:00:00'))].copy()\n",
    "spread_train = ((df_02['market2_bid_price0'] / df_02['market1_bid_price0']) - 1) * 10000\n",
    "print(spread_train.quantile(0.05),spread_train.quantile(0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train.apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train.quantile(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train.quantile(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train.quantile(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train.quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(spread_train, bins=200)  # 把bins设得很大，比如200\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram with many bins')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'BTC'\n",
    "st='2025-07-02'\n",
    "et='2025-07-15'\n",
    "exchange1='binance' \n",
    "market1='swap'\n",
    "exchange2='okx'     \n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "order_type = 'MT'\n",
    "data_source = \"outer_ssd\"\n",
    "\n",
    "\n",
    "cf_depth = read_cf_depth(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cols = ['index', 'market1_received_time', 'market1_E', 'market1_bid_price0',\n",
    "       'market1_bid_size0',\n",
    "       'market1_ask_price0', 'market1_ask_size0','market1_ws_type', 'market2_received_time',\n",
    "       'market2_E', 'market2_bid_price0', 'market2_bid_size0',\n",
    "        'market2_ask_price0',\n",
    "       'market2_ask_size0',\n",
    "       'market2_ws_type', 'ws_type', 'sp_open', 'sp_close', 'sr_open',\n",
    "       'sr_close', 'midprice', 'ret_mid_1.0s', 'logret_mid_1.0s','ret_mid_5.0s',\n",
    "       'ret_mid_10.0s', 'logret_mid_10.0s', 'ret_mid_30.0s',\n",
    "       'logret_mid_30.0s', 'ret_mid_60.0s', 'logret_mid_60.0s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth[show_cols].to_csv('/Users/rayxu/Desktop/Obentech/cf_depth_BTC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'BTC'\n",
    "st='2025-07-11'\n",
    "et='2025-07-11'\n",
    "train_st='2025-07-11'\n",
    "train_et='2025-07-11'\n",
    "exchange1='binance' \n",
    "market1='swap'\n",
    "exchange2='okx'     \n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "order_type = 'MT'\n",
    "data_source = \"outer_ssd\"\n",
    "\n",
    "\n",
    "\n",
    "cf_depth_train = read_cf_depth(ccy, train_st, train_et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "cf_depth = read_cf_depth(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "\n",
    "\n",
    "spread_train = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)\n",
    "\n",
    "target_open_sr = q90_train/10000\n",
    "target_close_sr = q10_train/10000\n",
    "\n",
    "cf_depth = plot_bid_price_spread_plotly(cf_depth, 'market2_ask_price0','market1_ask_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_train = ((cf_depth_train['market1_bid_price0'] / cf_depth_train['market2_bid_price0']) - 1) * 10000\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q90_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'ETH'\n",
    "st='2025-11-01'\n",
    "et='2025-11-05'\n",
    "exchange1='binance' \n",
    "market1='swap'\n",
    "exchange2='okx'     \n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "order_type = 'MT'\n",
    "data_source = \"nuts_mm\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cf_depth = read_cf_depth(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "cf_depth = read_cf_depth_backtesting(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "cf_depth_train = cf_depth.copy()\n",
    "\n",
    "spread_bid = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "spread_ask = ((cf_depth_train['market2_ask_price0'] / cf_depth_train['market1_ask_price0']) - 1) * 10000\n",
    "q10_train = spread_bid.quantile(close_quantile)\n",
    "q90_train = spread_ask.quantile(open_quantile)\n",
    "\n",
    "target_open_sr = q90_train/10000\n",
    "target_close_sr = q10_train/10000\n",
    "\n",
    "# plot_bid_price_spread_plotly(cf_depth, 'market2_ask_price0','market1_ask_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 帮我只画一下beijingtime 20250710 21:59 - 20250710 22:05的图\n",
    "start_time = pd.Timestamp('2025-07-11 05:50:00', tz='Asia/Shanghai')\n",
    "end_time = pd.Timestamp('2025-07-11 05:55:00', tz='Asia/Shanghai')\n",
    "cf_depth_sel = cf_depth[(cf_depth['beijing_time'] >= start_time) & (cf_depth['beijing_time'] <= end_time)]\n",
    "plot_bid_price_spread_plotly(cf_depth_sel, 'market2_ask_price0','market1_ask_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'ETH'\n",
    "st='2025-07-09'\n",
    "et='2025-07-09'\n",
    "train_st='2025-07-09'\n",
    "train_et='2025-07-09'\n",
    "exchange1='binance' \n",
    "market1='swap'\n",
    "exchange2='okx'     \n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "order_type = 'MT'\n",
    "data_source = \"outer_ssd\"\n",
    "\n",
    "\n",
    "\n",
    "cf_depth_train = read_cf_depth(ccy, train_st, train_et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "cf_depth = read_cf_depth(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "\n",
    "\n",
    "spread_train = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)\n",
    "\n",
    "target_open_sr = q90_train/10000\n",
    "target_close_sr = q10_train/10000\n",
    "\n",
    "plot_bid_price_spread_plotly(cf_depth, 'market1_bid_price0','market2_bid_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spread_train = ((cf_depth_train['market1_bid_price0'] / cf_depth_train['market2_bid_price0']) - 1) * 10000\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)\n",
    "print(q10_train,q90_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spread_train = ((cf_depth_train['market1_ask_price0'] / cf_depth_train['market2_ask_price0']) - 1) * 10000\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)\n",
    "print(q10_train,q90_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spread_train = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)\n",
    "print(q10_train,q90_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q90_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'ETH'\n",
    "st='2025-07-07'\n",
    "et='2025-07-07'\n",
    "train_st='2025-07-07'\n",
    "train_et='2025-07-07'\n",
    "exchange1='binance' \n",
    "market1='swap'\n",
    "exchange2='okx'     \n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "order_type = 'MT'\n",
    "data_source = \"outer_ssd\"\n",
    "\n",
    "\n",
    "\n",
    "cf_depth_train = read_cf_depth(ccy, train_st, train_et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "cf_depth = read_cf_depth(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "\n",
    "\n",
    "spread_train = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)\n",
    "\n",
    "target_open_sr = q90_train/10000\n",
    "target_close_sr = q10_train/10000\n",
    "\n",
    "plot_bid_price_spread_plotly(cf_depth, 'market2_bid_price0','market1_bid_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth = plot_bid_price_spread_plotly(cf_depth, 'market2_bid_price0','market1_ask_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'ETH'\n",
    "st='2025-07-08'\n",
    "et='2025-07-08'\n",
    "train_st='2025-07-08'\n",
    "train_et='2025-07-08'\n",
    "exchange1='binance' \n",
    "market1='swap'\n",
    "exchange2='okx'     \n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "order_type = 'MT'\n",
    "data_source = \"outer_ssd\"\n",
    "\n",
    "\n",
    "\n",
    "cf_depth_train = read_cf_depth(ccy, train_st, train_et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "cf_depth = read_cf_depth(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "\n",
    "\n",
    "spread_train = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)\n",
    "\n",
    "target_open_sr = q90_train/10000\n",
    "target_close_sr = q10_train/10000\n",
    "\n",
    "plot_bid_price_spread_plotly(cf_depth, 'market2_bid_price0','market1_bid_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.031140+2*0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把index为 152320 和 152330的行在dataframe里面标黄出来\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "cf_depth['spread'] = (cf_depth['market2_bid_price0'] / cf_depth['market1_ask_price0']-1)*10000\n",
    "# cf_depth['spread_real'] = ((cf_depth['market2_ask_price0']/(cf_depth['market1_bid_price0']+2*0.00001))-1)*10000\n",
    "# 把index为 152320 和 152330的行在dataframe里面标黄出来\n",
    "\n",
    "# 创建一个样式对象来高亮显示特定行\n",
    "def highlight_rows(row):\n",
    "    if row['index'] in [47714, 47725]:\n",
    "        return ['background-color: yellow'] * len(row)\n",
    "    return [''] * len(row)\n",
    "\n",
    "# # 应用样式并显示DataFrame\n",
    "# # 注意：只有在Jupyter notebook中才能显示带样式的DataFrame\n",
    "# styled_df = cf_depth[cf_depth.index>pd.Timestamp('2025-06-13 00:07:30')].head(20).style.apply(highlight_rows, axis=1)\n",
    "# styled_df\n",
    "temp = cf_depth[cf_depth.beijing_time>pd.Timestamp('2025-07-07 05:41:12', tz='Asia/Shanghai')].head(40)\n",
    "temp = temp[~temp.index.duplicated(keep = 'last')]\n",
    "temp.style.apply(highlight_rows, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_depth[cf_depth.index>pd.Timestamp('2025-06-13 17:19:50')].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binance = pd.read_csv('/Volumes/T7/Obentech/dcdlData/binance/books/VINE/swap/vineusdt_2025-06-13_depth5.csv')\n",
    "df_binance['T'] = pd.to_datetime(df_binance['T'], unit = 'ms')\n",
    "df_binance['E'] = pd.to_datetime(df_binance['E'], unit = 'ms')\n",
    "df_binance[df_binance['T']>pd.Timestamp('2025-06-13 00:07:30')].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_okx = pd.read_csv('/Volumes/T7/Obentech/dcdlData/okx/books/VINE/swap/vineusdt_2025-06-13_depth5.csv')\n",
    "df_okx['T'] = pd.to_datetime(df_okx['T'], unit = 'ms')\n",
    "# df_okx['E'] = pd.to_datetime(df_okx['E'], unit = 'ms')\n",
    "df_okx[df_okx['T']>pd.Timestamp('2025-06-13 00:07:30')].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st='2025-06-12'\n",
    "et='2025-06-13'\n",
    "train_st='2025-06-11'\n",
    "train_et='2025-06-11'\n",
    "exchange1='binance'\n",
    "market1='swap'\n",
    "exchange2='okx'\n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "data_source = 'outer_ssd'\n",
    "market1_stop_loss_sr_delta = -0.003\n",
    "market2_stop_loss_sr_delta = -0.003\n",
    "open_replace_tick_num = 2\n",
    "close_replace_tick_num = 2\n",
    "open_tick_num = 1\n",
    "close_tick_num = 1\n",
    "stats, cum_pnl, trade_pnl, funding_pnl = run_arbitrage_workflow_MT(\n",
    "    'VINE', \n",
    "    st=st, \n",
    "    et=et,\n",
    "    train_st= train_st,\n",
    "    train_et= train_et,\n",
    "    exchange1= exchange1, \n",
    "    market1= market1,\n",
    "    exchange2= exchange2,      \n",
    "    market2= market2,\n",
    "    open_quantile = open_quantile,\n",
    "    close_quantile = close_quantile,\n",
    "    data_source = data_source,\n",
    "    open_replace_tick_num = open_replace_tick_num,\n",
    "    close_replace_tick_num = close_replace_tick_num,\n",
    "    open_tick_num = open_tick_num,\n",
    "    close_tick_num = close_tick_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maker_maker_backtest_rolling_0605(cf_depth, mt_params, param_df, pos_limit = np.inf):\n",
    "\n",
    "\n",
    "    open_replace_tick_num = mt_params[\"open_replace_tick_num\"]\n",
    "    close_replace_tick_num = mt_params[\"close_replace_tick_num\"]\n",
    "\n",
    "\n",
    "    market1_stop_loss_sr_delta = mt_params['market1_stop_loss_sr_delta']\n",
    "    market2_stop_loss_sr_delta = mt_params['market2_stop_loss_sr_delta']\n",
    "\n",
    "    \n",
    "\n",
    "    tick_size1 = infer_tick_size_from_column(cf_depth['market1_bid_price0'])\n",
    "    tick_ratio1 = round(tick_size1/cf_depth.iloc[-1]['market1_bid_price0'], 6)\n",
    "    round_num1 = int(np.log10(1/tick_size1))\n",
    "    tick_size2 = infer_tick_size_from_column(cf_depth['market2_bid_price0'])\n",
    "    tick_ratio2 = round(tick_size2/cf_depth.iloc[-1]['market2_bid_price0'], 6)\n",
    "    round_num2 = int(np.log10(1/tick_size2))\n",
    "    print(\"交易所1精度信息\", tick_size1, tick_ratio1, round_num1)\n",
    "    print(\"交易所2精度信息\", tick_size2, tick_ratio2, round_num2)\n",
    "    \n",
    "    is_open_market1_done = False\n",
    "    is_open_market2_done = False\n",
    "    is_open_market1_maker = False\n",
    "    is_open_market2_maker = False\n",
    "    open_market1_maker_price = None\n",
    "    open_market1_taker_price = None\n",
    "    open_market2_maker_price = None\n",
    "    open_market2_taker_price = None\n",
    "    market1_open_time = None\n",
    "    market2_open_time = None\n",
    "\n",
    "    is_close_market1_done = False\n",
    "    is_close_market2_done = False\n",
    "    is_close_market1_maker = False\n",
    "    is_close_market2_maker = False\n",
    "    close_market1_maker_price = None\n",
    "    close_market1_taker_price = None\n",
    "    close_market2_maker_price = None\n",
    "    close_market2_taker_price = None\n",
    "    market1_close_time = None\n",
    "    market2_close_time = None\n",
    "    \n",
    "    sr_open = None\n",
    "    sr_open_real = None\n",
    "    sr_close = None\n",
    "    sr_close_real = None\n",
    "\n",
    "\n",
    "    # 回测输出变量\n",
    "    open_trades = []\n",
    "    close_trades = []\n",
    "    position_count = 0\n",
    "\n",
    "    m1_ask_arr = cf_depth['market1_ask_price0'].values\n",
    "    m1_bid_arr = cf_depth['market1_bid_price0'].values\n",
    "    m2_ask_arr = cf_depth['market2_ask_price0'].values\n",
    "    m2_bid_arr = cf_depth['market2_bid_price0'].values\n",
    "    idx_arr = cf_depth.index.to_numpy()\n",
    "\n",
    "    for i in tqdm(range(len(cf_depth)), desc='Processing'):\n",
    "        idx = idx_arr[i]\n",
    "        market1_ask_price1 = m1_ask_arr[i]\n",
    "        market1_bid_price1 = m1_bid_arr[i]\n",
    "        market2_ask_price1 = m2_ask_arr[i]\n",
    "        market2_bid_price1 = m2_bid_arr[i]\n",
    "    # # for idx, ds in tqdm(cf_depth.iterrows(), total=len(cf_depth), desc='Processing'):\n",
    "    # #     #新加仓位限制\n",
    "\n",
    "    #     market1_ask_price1 = ds['market1_ask_price0']\n",
    "    #     market1_bid_price1 = ds['market1_bid_price0']\n",
    "    #     market2_ask_price1 = ds['market2_ask_price0']\n",
    "    #     market2_bid_price1 = ds['market2_bid_price0']\n",
    "        # print(f'{idx}, market1 ask:{market1_ask_price1} , market1 bid: {market1_bid_price1}')\n",
    "\n",
    "        current_time = idx\n",
    "        # 新加动态threshold的逻辑\n",
    "        update_time = param_df.index[param_df.index <= current_time].max()\n",
    "        sr_open_threshold = param_df.loc[update_time, 'adjusted_open']/10000\n",
    "        sr_close_threshold = param_df.loc[update_time, 'adjusted_close']/10000\n",
    "\n",
    "        # 改成TM的价差会好一点\n",
    "        sr_open = (market2_bid_price1)/(market1_ask_price1 - tick_size1 * 1) - 1\n",
    "        sr_close = (market2_ask_price1)/(market1_bid_price1 + tick_size1 * 1) - 1\n",
    "\n",
    "\n",
    "        # 把开平仓预设撤单价差作为撤单条件(实盘逻辑)\n",
    "        sr_open_cancel_threshold = sr_open_threshold\n",
    "        sr_close_cancel_threshold = sr_close_threshold\n",
    "        \n",
    "        # 下单判断\n",
    "        open_judgement = (sr_open >= sr_open_threshold)\n",
    "        close_judgement = (sr_close <= sr_close_threshold)\n",
    "        # 撤单判断\n",
    "        open_cancel_judgement = (sr_open < sr_open_cancel_threshold)\n",
    "        close_cancel_judgement = (sr_close > sr_close_cancel_threshold)\n",
    "\n",
    "        is_any_trade_in_progress = (\n",
    "            is_open_market1_maker  or \n",
    "            is_close_market1_maker \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if open_judgement and (not is_any_trade_in_progress) and (not is_open_market1_maker) and position_count < pos_limit:\n",
    "            open_market1_maker_price = round(market1_ask_price1 - tick_size1 * 1, round_num1)  #bid\n",
    "            is_open_market1_maker = True\n",
    "            # print(f'{idx},开仓挂单，当前价差: {sr_open}, {sr_close}, 当前threshold: {sr_open_threshold},{sr_close_threshold}, 开仓挂单，market1挂单价:{open_market1_maker_price}')\n",
    "        # 如果价差消失且没成交，撤单\n",
    "        if open_cancel_judgement and is_open_market1_maker:\n",
    "            is_open_market1_maker = False\n",
    "            # print(f'{idx},价差消失，开仓撤单，当前价差: {sr_open}, 当前threshold: {sr_open_threshold}')\n",
    "\n",
    "        # 如果双边都没有成交\n",
    "        if (is_open_market1_maker and (not is_open_market1_done)):\n",
    "            # 判断market1是否成交\n",
    "            if (market1_ask_price1 <= open_market1_maker_price):\n",
    "                is_open_market1_done = True\n",
    "                is_open_market1_maker = False\n",
    "                market1_open_time = idx\n",
    "                # print(f'{idx}, market1Maker成交：{open_market1_maker_price}')\n",
    "            if (market1_ask_price1 - open_market1_maker_price)> tick_size1 * open_replace_tick_num:         # 这个地方等于的逻辑是不是有点问题？ 如果价格不变的话，好像也在重新挂单。。。\n",
    "                # print(f'market1_ask_price1: {market1_ask_price1}, open_market1_maker_price: {open_market1_maker_price}, tick_size1: {tick_size1}, open_replace_tick_num: {open_replace_tick_num}')\n",
    "                open_market1_maker_price = round(market1_ask_price1 - tick_size1 * 1, round_num1)           # 这个地方是不是应该再进行一下撤单判断？ 不然有可能直接成交了； 好像不需要，因为到这一步了就说明market1，2都没有成交，就直接continue了。\n",
    "                # print(f'{idx}, market1Maker重新挂单，当前行为: buy, 当前ask_price: {market1_ask_price1}, 当前价差: {sr_open},当前threshold: {sr_open_threshold}, market1挂单价:{open_market1_maker_price}')\n",
    "        # 如果market1成交了\n",
    "        if is_open_market1_done and (not is_open_market2_done):\n",
    "            if open_market1_maker_price is None:\n",
    "                print(f'open_market1_maker_price is None at {idx}')\n",
    "            if sr_open_threshold is None:\n",
    "                print(f'sr_open_threshold is None at {idx}')\n",
    "            # 判读market2是否要taker对冲掉\n",
    "            if (market2_bid_price1/open_market1_maker_price - 1) <= (sr_open_threshold - market2_stop_loss_sr_delta):\n",
    "                open_market2_taker_price = market2_bid_price1\n",
    "                is_open_market2_done = True\n",
    "                sr_open_real = open_market2_taker_price/open_market1_maker_price - 1\n",
    "                market2_open_time = idx\n",
    "                open_trades.append([idx, sr_open, sr_open_real, open_market1_maker_price, open_market2_taker_price,\n",
    "                                    'market1_maker', 'market2_taker',\n",
    "                                    market1_open_time, market2_open_time])\n",
    "                # print(f'{idx}, market2Taker对冲， market2对冲价格：{open_market2_taker_price}')\n",
    "            # 判断market2是否成交\n",
    "            # elif market2_bid_price1 >= open_market2_maker_price:\n",
    "            #     is_open_market2_done = True\n",
    "            #     sr_open_real = open_market2_maker_price/open_market1_maker_price - 1\n",
    "            #     market2_open_time = idx\n",
    "            #     open_trades.append([idx, sr_open, sr_open_real, open_market1_maker_price, open_market2_maker_price,\n",
    "            #                         'market1_maker', 'market2_maker',\n",
    "            #                         market1_open_time, market2_open_time])\n",
    "            #     print('sb')\n",
    "\n",
    "        # 成交完成，重置\n",
    "        if is_open_market1_done and is_open_market2_done:\n",
    "            position_count += 1\n",
    "            is_open_market1_done = False\n",
    "            is_open_market2_done = False\n",
    "            is_open_market1_maker = False\n",
    "            open_market1_maker_price = None\n",
    "            open_market2_maker_price = None\n",
    "            open_market2_taker_price = None\n",
    "            market1_open_time = None\n",
    "            market2_open_time = None\n",
    "\n",
    "\n",
    "        # 平仓\n",
    "        # print(close_judgement,is_close_market1_maker,is_close_market2_maker)\n",
    "        if close_judgement and (not is_any_trade_in_progress) and (not is_close_market1_maker) and (position_count > -pos_limit):\n",
    "            close_market1_maker_price = round(market1_bid_price1 + tick_size1 * 1, round_num1)\n",
    "            is_close_market1_maker = True\n",
    "            print(f'{idx}, 平仓挂单，当前价差: {sr_open}, {sr_close}, 当前threshold: {sr_open_threshold},{sr_close_threshold}, market1挂单价:{close_market1_maker_price}')\n",
    "\n",
    "        # 如果价差消失且没成交，撤单\n",
    "        if close_cancel_judgement and is_close_market1_maker:\n",
    "            is_close_market1_maker = False\n",
    "            # print(f'{idx},价差消失，平仓撤单，当前价差: {sr_close}, 当前threshold: {sr_close_threshold}')\n",
    "\n",
    "        # 如果边都没有成交\n",
    "        if (is_close_market1_maker and (not is_close_market1_done)):\n",
    "            # 判断market1是否成交\n",
    "            if (market1_bid_price1 >= close_market1_maker_price):\n",
    "                is_close_market1_done = True\n",
    "                is_close_market1_maker = False\n",
    "                market1_close_time = idx\n",
    "                print(f'{idx}, market1Maker成交：{close_market1_maker_price}')\n",
    "            # 判断是否重新挂单\n",
    "            if (close_market1_maker_price - market1_bid_price1)> tick_size1 * close_replace_tick_num:\n",
    "                # print(f'market1_bid_price1: {market1_bid_price1}, close_market1_maker_price: {close_market1_maker_price}, tick_size1: {tick_size1}, close_replace_tick_num: {close_replace_tick_num}')\n",
    "                close_market1_maker_price = round(market1_bid_price1 + tick_size1 * close_replace_tick_num, round_num1)\n",
    "                # print(f'{idx}, market1Maker重新挂单，当前行为: sell, 当前bid_price: {market1_bid_price1}, 当前价差: {sr_close},当前threshold: {sr_close_threshold}, market1新的挂单价:{close_market1_maker_price}')\n",
    "\n",
    "        # 如果market1成交了\n",
    "        if is_close_market1_done and (not is_close_market2_done):\n",
    "            # 判断market2是否要taker对冲掉\n",
    "            if (market2_ask_price1/close_market1_maker_price - 1) >= (sr_close_threshold + market2_stop_loss_sr_delta):\n",
    "                close_market2_taker_price = market2_ask_price1\n",
    "                is_close_market2_done = True\n",
    "                is_close_market2_maker = False\n",
    "                sr_close_real = close_market2_taker_price/close_market1_maker_price - 1\n",
    "                close_trades.append([idx, sr_close, sr_close_real, close_market1_maker_price, close_market2_taker_price,\n",
    "                                     'market1_maker', 'market2_taker',\n",
    "                                     market1_close_time, market2_close_time])\n",
    "                print(f'{idx}, marke2Taker成交：{close_market2_taker_price}')\n",
    "            # # 判断market2是否成交\n",
    "        #     elif market2_ask_price1 <= close_market2_maker_price:\n",
    "        #         is_close_market2_done = True\n",
    "        #         is_close_market2_maker = False\n",
    "        #         sr_close_real = close_market2_maker_price/close_market1_maker_price - 1\n",
    "        #         market2_close_time = idx\n",
    "        #         close_trades.append([idx, sr_close, sr_close_real, close_market1_maker_price, close_market2_maker_price,\n",
    "        #                              'market1_maker', 'market2_maker',\n",
    "        #                              market1_close_time, market2_close_time])\n",
    "        # ###        print(f'{index}, marke2Maker成交：{close_market2_maker_price}')\n",
    "        #     # 判断market2是否重挂\n",
    "        #     elif (market2_ask_price1 - close_market2_maker_price)> tick_size2 * close_replace_tick_num:\n",
    "        #             close_market2_maker_price = round(market2_ask_price1 - tick_size2 * 1, round_num2)\n",
    "            \n",
    "        # 成交完成，重置\n",
    "        if is_close_market1_done and is_close_market2_done:\n",
    "            position_count -= 1\n",
    "            is_close_market1_done = False\n",
    "            is_close_market2_done = False\n",
    "            is_close_market1_maker = False\n",
    "            is_close_market2_maker = False\n",
    "            close_market1_maker_price = None\n",
    "            close_market2_maker_price = None\n",
    "            close_market2_taker_price = None\n",
    "            market1_close_time = None\n",
    "            market2_close_time = None\n",
    "            \n",
    "\n",
    "        # except Exception as e:\n",
    "                # traceback.print_exc()\n",
    "    \n",
    "    open_trades_df = pd.DataFrame(open_trades, columns=['index', 'sr_open', 'sr_open_real', \n",
    "                                                        'market1_traded_price', 'market2_traded_price',\n",
    "                                                        'market1_traded_type', 'market2_traded_type',\n",
    "                                                        'market1_open_time', 'market2_open_time'])\n",
    "    open_trades_df.set_index('index', inplace=True)\n",
    "    close_trades_df = pd.DataFrame(close_trades, columns=['index', 'sr_close', 'sr_close_real', \n",
    "                                                        'market1_traded_price', 'market2_traded_price',\n",
    "                                                        'market1_traded_type', 'market2_traded_type',\n",
    "                                                        'market1_close_time', 'market2_close_time'])\n",
    "    close_trades_df.set_index('index', inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    return open_trades_df, close_trades_df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'VINE'\n",
    "if data_source == 'inner_win':\n",
    "    funding_okx_csv = f'/Users/rayxu/Desktop/Obentech/fundingRateData/okx/{ccy}-USDT-SWAP.csv'\n",
    "    funding_binance_csv = f'/Users/rayxu/Desktop/Obentech/fundingRateData/binance/{ccy}USDT.csv'\n",
    "elif data_source == 'outer_ssd':\n",
    "    funding_okx_csv = f'/Volumes/T7/Obentech/fundingRateData/okx/{ccy}-USDT-SWAP.csv'\n",
    "    funding_binance_csv = f'/Volumes/T7/Obentech/fundingRateData/binance/{ccy}USDT.csv'        \n",
    "\n",
    "df_okx      = process_funding_time(funding_okx_csv,  exchange='okx')\n",
    "df_binance  = process_funding_time(funding_binance_csv,  exchange='binance')\n",
    "\n",
    "fr_okx      = funding_df_to_series(df_okx)       # OKX\n",
    "fr_binance  = funding_df_to_series(df_binance)   # Binance\n",
    "\n",
    "\n",
    "\n",
    "time_index = \"local_time\"\n",
    "cf_depth = read_cf_depth(ccy, train_st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "\n",
    "\n",
    "# spread_train = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "# capital = 0\n",
    "mean_price =0.5*(cf_depth['market2_bid_price0'].dropna().mean() + cf_depth['market1_bid_price0'].dropna().mean())\n",
    "\n",
    "capital = 10000\n",
    "single_order_amount = 100\n",
    "single_order_volume = 100/ mean_price\n",
    "notional = single_order_volume\n",
    "pos_limit = capital/(2*single_order_amount)\n",
    "look_back_days = 3\n",
    "z_threshold = 1.64\n",
    "\n",
    "\n",
    "param_df = generate_param_df(cf_depth,df_okx, df_binance,ccy,look_back_days,z_threshold,freq= '1D')\n",
    "\n",
    "# 让cf_depth的日期大于等于st 加上16小时\n",
    "cf_depth = cf_depth[cf_depth.index >= pd.to_datetime(st) - pd.Timedelta(hours=8)]\n",
    "cf_depth = cf_depth[~cf_depth.index.duplicated(keep='last')]\n",
    "\n",
    "taker_traded_delay_seconds = 0.02\n",
    "maker_ordered_delay_seconds = 0.01\n",
    "\n",
    "\n",
    "mt_params = {'open_tick_num':open_tick_num, 'open_replace_tick_num':open_replace_tick_num,\n",
    "            'close_tick_num':close_tick_num, 'close_replace_tick_num':close_replace_tick_num, \n",
    "            'taker_traded_delay_seconds':taker_traded_delay_seconds, 'maker_ordered_delay_seconds':maker_ordered_delay_seconds,\n",
    "            'market1_stop_loss_sr_delta':market1_stop_loss_sr_delta, 'market2_stop_loss_sr_delta':market2_stop_loss_sr_delta,\n",
    "            'exchange1_type':exchange1, 'market1_type':market1, 'exchange2_type':exchange2, 'market2_type':market2}\n",
    "\n",
    "open_trades_df, close_trades_df = maker_maker_backtest_rolling_0605(cf_depth, mt_params,param_df,pos_limit= pos_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_rows(row):\n",
    "    if row.name == pd.to_datetime('2025-06-13 00:07:30.590000'):\n",
    "        return ['background-color: yellow'] * len(row)\n",
    "    return [''] * len(row)\n",
    "\n",
    "close_trades_df.tail(20).style.apply(highlight_rows, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bid_price_spread_plotly(cf_depth, 'market2_ask_price0','market1_ask_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccy = 'VINE'\n",
    "st='2025-06-11'\n",
    "et='2025-06-13'\n",
    "train_st='2025-06-11'\n",
    "train_et='2025-06-11'\n",
    "exchange1='binance' \n",
    "market1='swap'\n",
    "exchange2='okx'     \n",
    "market2='swap'\n",
    "open_quantile = 0.95\n",
    "close_quantile = 0.05\n",
    "order_type = 'MT'\n",
    "data_source = \"outer_ssd\"\n",
    "\n",
    "\n",
    "\n",
    "cf_depth_train = read_cf_depth(ccy, train_st, train_et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "cf_depth = read_cf_depth(ccy, st, et, exchange1, market1, exchange2, market2, data_source=data_source)\n",
    "\n",
    "\n",
    "spread_train = ((cf_depth_train['market2_bid_price0'] / cf_depth_train['market1_bid_price0']) - 1) * 10000\n",
    "q10_train = spread_train.quantile(close_quantile)\n",
    "q90_train = spread_train.quantile(open_quantile)\n",
    "\n",
    "target_open_sr = q90_train/10000\n",
    "target_close_sr = q10_train/10000\n",
    "\n",
    "plot_bid_price_spread_plotly(cf_depth, 'market2_ask_price0','market1_ask_price0',q_10_bt=target_close_sr*10000,q_90_bt=target_open_sr*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_pnl_dict (1).pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 打开pickle文件\n",
    "with open('/Users/rayxu/Downloads/symbol_pnl_dict (1).pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
